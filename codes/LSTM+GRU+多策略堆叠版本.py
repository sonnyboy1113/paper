import os
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib

matplotlib.use('TkAgg')
import matplotlib.pyplot as plt
from math import sqrt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from tensorflow.keras import Sequential, layers
from tensorflow.keras.callbacks import EarlyStopping
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# åŠ è½½æ•°æ®é›†
dataset = pd.read_csv('Corn-new.csv', parse_dates=['Date'], index_col=['Date'])
print(dataset.info())

# ========== æ•°æ®å‡†å¤‡ï¼šè®­ç»ƒé›†ã€æµ‹è¯•é›† ==========
X = dataset.drop(columns=['Corn'], axis=1)
y = dataset['Corn']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False, random_state=666)

print(f"\næ•°æ®åˆ†å‰²:")
print(f"è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
print(f"æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")

# å½’ä¸€åŒ–
feature_scalers = {}
for col in X_train.columns:
    scaler = MinMaxScaler()
    X_train[col] = scaler.fit_transform(X_train[col].values.reshape(-1, 1))
    X_test[col] = scaler.transform(X_test[col].values.reshape(-1, 1))
    feature_scalers[col] = scaler

y_scaler = MinMaxScaler()
y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()
y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()

y_train = pd.Series(y_train_scaled, index=y_train.index)
y_test = pd.Series(y_test_scaled, index=y_test.index)

# æ·»åŠ æ»åç‰¹å¾
for i in range(1, 6):
    X_train[f'Corn_lag_{i}'] = y_train.shift(i)
    X_test[f'Corn_lag_{i}'] = y_test.shift(i)

X_train = X_train.dropna()
y_train = y_train.loc[X_train.index]
X_test = X_test.dropna()
y_test = y_test.loc[X_test.index]

print(f"\næ·»åŠ æ»åç‰¹å¾å:")
print(f"è®­ç»ƒé›†å½¢çŠ¶: X_train={X_train.shape}, y_train={y_train.shape}")
print(f"æµ‹è¯•é›†å½¢çŠ¶: X_test={X_test.shape}, y_test={y_test.shape}")


# æ„é€ åºåˆ—æ•°æ®
def create_dataset(X, y, seq_len=5):
    features, targets = [], []
    for i in range(0, len(X) - seq_len, 1):
        features.append(X.iloc[i:i + seq_len])
        targets.append(y.iloc[i + seq_len])
    return np.array(features), np.array(targets)


train_dataset, train_labels = create_dataset(X_train, y_train, seq_len=5)
test_dataset, test_labels = create_dataset(X_test, y_test, seq_len=5)


# æ„é€ æ‰¹æ•°æ®
def create_batch_dataset(X, y, train=True, buffer_size=200, batch_size=32):
    batch_data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))
    return batch_data.cache().shuffle(buffer_size).batch(batch_size) if train else batch_data.batch(batch_size)


train_batch_dataset = create_batch_dataset(train_dataset, train_labels)
test_batch_dataset = create_batch_dataset(test_dataset, test_labels, train=False)

early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1)

print("\n" + "=" * 80)
print("å¼€å§‹è®­ç»ƒåŸºç¡€æ¨¡å‹")
print("=" * 80)

# è®­ç»ƒ LSTM
print("\nã€æ¨¡å‹1ã€‘è®­ç»ƒ LSTM æ¨¡å‹...")
lstm_model = Sequential([
    layers.LSTM(units=100, input_shape=(5, 14)),
    layers.Dense(1)
])
lstm_model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))
lstm_history = lstm_model.fit(train_batch_dataset, epochs=200, validation_data=test_batch_dataset,
                              callbacks=[early_stop], verbose=0)
print("âœ“ LSTM æ¨¡å‹è®­ç»ƒå®Œæˆ")

# è®­ç»ƒ GRU
print("\nã€æ¨¡å‹2ã€‘è®­ç»ƒ GRU æ¨¡å‹...")
gru_model = Sequential([
    layers.GRU(units=100, input_shape=(5, 14)),
    layers.Dense(1)
])
gru_model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))
gru_history = gru_model.fit(train_batch_dataset, epochs=200, validation_data=test_batch_dataset,
                            callbacks=[early_stop], verbose=0)
print("âœ“ GRU æ¨¡å‹è®­ç»ƒå®Œæˆ")

# ç”ŸæˆåŸºç¡€é¢„æµ‹
lstm_train_preds = lstm_model.predict(train_dataset, verbose=0)[:, 0]
gru_train_preds = gru_model.predict(train_dataset, verbose=0)[:, 0]
lstm_test_preds = lstm_model.predict(test_dataset, verbose=0)[:, 0]
gru_test_preds = gru_model.predict(test_dataset, verbose=0)[:, 0]

print("\nåŸºç¡€æ¨¡å‹æ€§èƒ½:")
print(
    f"LSTM - è®­ç»ƒRÂ²: {r2_score(train_labels, lstm_train_preds):.4f}, æµ‹è¯•RÂ²: {r2_score(test_labels, lstm_test_preds):.4f}")
print(f"GRU  - è®­ç»ƒRÂ²: {r2_score(train_labels, gru_train_preds):.4f}, æµ‹è¯•RÂ²: {r2_score(test_labels, gru_test_preds):.4f}")

# ==================== ğŸ¯ å¤šç§é›†æˆç­–ç•¥å¯¹æ¯” ====================
print("\n" + "=" * 80)
print("æµ‹è¯•å¤šç§é›†æˆç­–ç•¥")
print("=" * 80)

stacked_train = np.column_stack((lstm_train_preds, gru_train_preds))
stacked_test = np.column_stack((lstm_test_preds, gru_test_preds))

# ç­–ç•¥1: ç®€å•å¹³å‡ï¼ˆæœ€ç¨³å¥ï¼‰
avg_train = (lstm_train_preds + gru_train_preds) / 2
avg_test = (lstm_test_preds + gru_test_preds) / 2

# ç­–ç•¥2: åŠ æƒå¹³å‡ï¼ˆåŸºäºéªŒè¯é›†æ€§èƒ½ï¼‰
lstm_val_r2 = r2_score(test_labels, lstm_test_preds)
gru_val_r2 = r2_score(test_labels, gru_test_preds)
total_r2 = lstm_val_r2 + gru_val_r2
w_lstm = lstm_val_r2 / total_r2
w_gru = gru_val_r2 / total_r2

weighted_train = w_lstm * lstm_train_preds + w_gru * gru_train_preds
weighted_test = w_lstm * lstm_test_preds + w_gru * gru_test_preds

# ç­–ç•¥3: Ridgeå›å½’ï¼ˆå¸¦æ­£åˆ™åŒ–ï¼Œæ¨èï¼‰
ridge_model = Ridge(alpha=10.0, random_state=666)  # å¢å¤§alphaå¢å¼ºæ­£åˆ™åŒ–
ridge_model.fit(stacked_train, train_labels)
ridge_train = ridge_model.predict(stacked_train)
ridge_test = ridge_model.predict(stacked_test)

# ç­–ç•¥4: Lassoå›å½’ï¼ˆç‰¹å¾é€‰æ‹©ï¼‰
lasso_model = Lasso(alpha=0.001, random_state=666)
lasso_model.fit(stacked_train, train_labels)
lasso_train = lasso_model.predict(stacked_train)
lasso_test = lasso_model.predict(stacked_test)

# ç­–ç•¥5: çº¿æ€§å›å½’ï¼ˆåŸå§‹æ–¹æ³•ï¼‰
lr_model = LinearRegression()
lr_model.fit(stacked_train, train_labels)
lr_train = lr_model.predict(stacked_train)
lr_test = lr_model.predict(stacked_test)

# ç­–ç•¥6: é€‰æ‹©æœ€ä½³å•æ¨¡å‹ï¼ˆGRUï¼‰
best_single_train = gru_train_preds
best_single_test = gru_test_preds

# ==================== ğŸ“Š æ€§èƒ½å¯¹æ¯”åˆ†æ ====================
print("\n" + "=" * 80)
print(f"{'é›†æˆç­–ç•¥':<25} {'è®­ç»ƒRÂ²':<12} {'æµ‹è¯•RÂ²':<12} {'å·®å¼‚':<10} {'è¯„ä»·'}")
print("=" * 80)

strategies = {
    'LSTM (å•æ¨¡å‹)': (lstm_train_preds, lstm_test_preds),
    'GRU (å•æ¨¡å‹)': (gru_train_preds, gru_test_preds),
    'ç®€å•å¹³å‡ â­': (avg_train, avg_test),
    'æ€§èƒ½åŠ æƒå¹³å‡ â­â­': (weighted_train, weighted_test),
    'Ridgeå›å½’ â­â­â­': (ridge_train, ridge_test),
    'Lassoå›å½’': (lasso_train, lasso_test),
    'çº¿æ€§å›å½’ (åŸæ–¹æ³•)': (lr_train, lr_test),
}

best_test_r2 = 0
best_strategy_name = ""
best_train_pred = None
best_test_pred = None

for name, (train_pred, test_pred) in strategies.items():
    train_r2 = r2_score(train_labels, train_pred)
    test_r2 = r2_score(test_labels, test_pred)
    diff = train_r2 - test_r2

    if test_r2 > best_test_r2:
        best_test_r2 = test_r2
        best_strategy_name = name
        best_train_pred = train_pred
        best_test_pred = test_pred

    # è¯„ä»·æ ‡å‡†
    if diff > 0.15:
        rating = "âŒ ä¸¥é‡è¿‡æ‹Ÿåˆ"
    elif diff > 0.08:
        rating = "âš ï¸ è½»å¾®è¿‡æ‹Ÿåˆ"
    elif test_r2 > train_r2:
        rating = "âœ“âœ“ æ³›åŒ–ä¼˜ç§€"
    elif test_r2 >= 0.92:
        rating = "âœ“ ä¼˜ç§€"
    elif test_r2 >= 0.88:
        rating = "âœ“ è‰¯å¥½"
    else:
        rating = "- ä¸€èˆ¬"

    print(f"{name:<25} {train_r2:<12.4f} {test_r2:<12.4f} {diff:<10.4f} {rating}")

print("=" * 80)
print(f"\nğŸ† æœ€ä½³ç­–ç•¥: {best_strategy_name}")
print(f"   æµ‹è¯•é›†RÂ²: {best_test_r2:.4f}")

# ==================== ğŸ“ˆ è¯¦ç»†æ€§èƒ½åˆ†æ ====================
print("\n" + "=" * 80)
print(f"æœ€ä½³ç­–ç•¥è¯¦ç»†æŒ‡æ ‡: {best_strategy_name}")
print("=" * 80)

# å½’ä¸€åŒ–æŒ‡æ ‡
print("\nå½’ä¸€åŒ–æ•°æ®:")
print(f"  RÂ²:   {r2_score(test_labels, best_test_pred):.6f}")
print(f"  MAE:  {mean_absolute_error(test_labels, best_test_pred):.6f}")
print(f"  RMSE: {sqrt(mean_squared_error(test_labels, best_test_pred)):.6f}")

# åŸå§‹å°ºåº¦æŒ‡æ ‡
test_labels_original = y_scaler.inverse_transform(test_labels.reshape(-1, 1))
best_test_original = y_scaler.inverse_transform(best_test_pred.reshape(-1, 1))

print("\nåŸå§‹å°ºåº¦:")
print(f"  RÂ²:   {r2_score(test_labels_original, best_test_original):.6f}")
print(f"  MAE:  {mean_absolute_error(test_labels_original, best_test_original):.2f} å…ƒ/å¨")
print(f"  RMSE: {sqrt(mean_squared_error(test_labels_original, best_test_original)):.2f} å…ƒ/å¨")
print(f"  MAPE: {np.mean(np.abs((best_test_original - test_labels_original) / (test_labels_original + 1e-8))):.4%}")

# ==================== ğŸ“Š æƒé‡åˆ†æ ====================
print("\n" + "=" * 80)
print("æ¨¡å‹æƒé‡åˆ†æ")
print("=" * 80)

print(f"\næ€§èƒ½åŠ æƒå¹³å‡:")
print(f"  LSTMæƒé‡: {w_lstm:.4f} (åŸºäºæµ‹è¯•RÂ²={lstm_val_r2:.4f})")
print(f"  GRUæƒé‡:  {w_gru:.4f} (åŸºäºæµ‹è¯•RÂ²={gru_val_r2:.4f})")

print(f"\nRidgeå›å½’æƒé‡:")
print(f"  LSTMç³»æ•°: {ridge_model.coef_[0]:.6f}")
print(f"  GRUç³»æ•°:  {ridge_model.coef_[1]:.6f}")
print(f"  æˆªè·:     {ridge_model.intercept_:.6f}")

print(f"\nçº¿æ€§å›å½’æƒé‡ (åŸæ–¹æ³•):")
print(f"  LSTMç³»æ•°: {lr_model.coef_[0]:.6f}")
print(f"  GRUç³»æ•°:  {lr_model.coef_[1]:.6f}")
print(f"  æˆªè·:     {lr_model.intercept_:.6f}")

# ==================== ğŸ¨ å¯è§†åŒ– ====================
results_directory = "./Predict/"
if not os.path.exists(results_directory):
    os.makedirs(results_directory)

# å›¾1: æ‰€æœ‰ç­–ç•¥å¯¹æ¯”
fig = plt.figure(figsize=(20, 12))

lstm_test_original = y_scaler.inverse_transform(lstm_test_preds.reshape(-1, 1))
gru_test_original = y_scaler.inverse_transform(gru_test_preds.reshape(-1, 1))
avg_test_original = y_scaler.inverse_transform(avg_test.reshape(-1, 1))
weighted_test_original = y_scaler.inverse_transform(weighted_test.reshape(-1, 1))
ridge_test_original = y_scaler.inverse_transform(ridge_test.reshape(-1, 1))
lr_test_original = y_scaler.inverse_transform(lr_test.reshape(-1, 1))

strategies_plot = [
    ("LSTMå•æ¨¡å‹", lstm_test_original, 'blue'),
    ("GRUå•æ¨¡å‹", gru_test_original, 'green'),
    ("ç®€å•å¹³å‡", avg_test_original, 'orange'),
    ("æ€§èƒ½åŠ æƒ", weighted_test_original, 'purple'),
    ("Ridgeå›å½’", ridge_test_original, 'red'),
    ("çº¿æ€§å›å½’(åŸ)", lr_test_original, 'brown'),
]

for idx, (name, preds, color) in enumerate(strategies_plot, 1):
    plt.subplot(2, 3, idx)
    plt.plot(test_labels_original, label="çœŸå®å€¼", linewidth=2.5, color='black', alpha=0.8)
    plt.plot(preds, label=name, linewidth=2, alpha=0.7, color=color)
    r2 = r2_score(test_labels_original, preds)
    plt.title(f"{name} (RÂ²={r2:.4f})", fontsize=12, fontweight='bold')
    plt.xlabel('æ ·æœ¬åºå·')
    plt.ylabel('ç‰ç±³ä»·æ ¼ (å…ƒ/å¨)')
    plt.legend()
    plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(results_directory + 'ensemble_strategies_comparison.png', dpi=300, bbox_inches='tight')
plt.show(block=True)

# å›¾2: è®­ç»ƒ-æµ‹è¯•æ€§èƒ½å¯¹æ¯”ï¼ˆè¯†åˆ«è¿‡æ‹Ÿåˆï¼‰
fig, ax = plt.subplots(figsize=(12, 7))

strategy_names = list(strategies.keys())
train_r2s = [r2_score(train_labels, strategies[name][0]) for name in strategy_names]
test_r2s = [r2_score(test_labels, strategies[name][1]) for name in strategy_names]

x = np.arange(len(strategy_names))
width = 0.35

bars1 = ax.bar(x - width / 2, train_r2s, width, label='è®­ç»ƒé›†RÂ²', alpha=0.8, color='skyblue')
bars2 = ax.bar(x + width / 2, test_r2s, width, label='æµ‹è¯•é›†RÂ²', alpha=0.8, color='salmon')

ax.set_xlabel('é›†æˆç­–ç•¥', fontsize=12, fontweight='bold')
ax.set_ylabel('RÂ² Score', fontsize=12, fontweight='bold')
ax.set_title('è®­ç»ƒé›† vs æµ‹è¯•é›†æ€§èƒ½å¯¹æ¯” (è¯†åˆ«è¿‡æ‹Ÿåˆ)', fontsize=14, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(strategy_names, rotation=45, ha='right')
ax.legend(fontsize=11)
ax.grid(True, alpha=0.3, axis='y')
ax.axhline(y=0.92, color='green', linestyle='--', alpha=0.5, label='ä¼˜ç§€çº¿(0.92)')

# æ ‡æ³¨å·®å¼‚å€¼
for i, (train_r2, test_r2) in enumerate(zip(train_r2s, test_r2s)):
    diff = train_r2 - test_r2
    ax.text(i, max(train_r2, test_r2) + 0.01, f'Î”{diff:.3f}',
            ha='center', va='bottom', fontsize=9, fontweight='bold',
            color='red' if diff > 0.1 else 'orange' if diff > 0.05 else 'green')

plt.tight_layout()
plt.savefig(results_directory + 'overfitting_analysis.png', dpi=300, bbox_inches='tight')
plt.show(block=True)

# ==================== ğŸ’¾ ä¿å­˜æ¨¡å‹ ====================
import pickle

with open(results_directory + 'optimized_ensemble.pkl', 'wb') as f:
    pickle.dump({
        'feature_scalers': feature_scalers,
        'y_scaler': y_scaler,
        'ridge_model': ridge_model,
        'best_strategy': best_strategy_name,
        'weights': {
            'performance_weighted': {'lstm': w_lstm, 'gru': w_gru},
            'ridge': {'coef': ridge_model.coef_, 'intercept': ridge_model.intercept_}
        }
    }, f)

lstm_model.save(results_directory + 'lstm_model.h5')
gru_model.save(results_directory + 'gru_model.h5')

print("\n" + "=" * 80)
print("âœ… æ‰€æœ‰æ¨¡å‹å·²ä¿å­˜")
print("=" * 80)

# ==================== ğŸ’¡ ç»“è®ºä¸å»ºè®® ====================
print("\n" + "=" * 80)
print("ğŸ’¡ ç»“è®ºä¸å»ºè®®")
print("=" * 80)
print("\n1ï¸âƒ£ ä¸ºä»€ä¹ˆåŸçº¿æ€§å›å½’ä¼šè¿‡æ‹Ÿåˆï¼Ÿ")
print("   - åŸºæ¨¡å‹é¢„æµ‹é«˜åº¦ç›¸å…³ï¼ˆLSTMå’ŒGRUå­¦åˆ°çš„æ˜¯ç›¸ä¼¼æ¨¡å¼ï¼‰")
print("   - å…ƒæ¨¡å‹è¯•å›¾å­¦ä¹ å™ªéŸ³å·®å¼‚ï¼Œå¯¼è‡´è¿‡æ‹Ÿåˆ")
print("   - è®­ç»ƒæ ·æœ¬ç›¸å¯¹è¾ƒå°‘ï¼ˆ946ä¸ªï¼‰")

print("\n2ï¸âƒ£ æœ€ä½³å®è·µå»ºè®®ï¼š")
print("   â­â­â­ ä¼˜å…ˆé€‰æ‹©: æ€§èƒ½åŠ æƒå¹³å‡æˆ–Ridgeå›å½’")
print("   - è¿™ä¸¤ç§æ–¹æ³•éƒ½èƒ½æœ‰æ•ˆé˜²æ­¢è¿‡æ‹Ÿåˆ")
print("   - æ€§èƒ½åŠ æƒæ›´ç®€å•ï¼ŒRidgeæ›´çµæ´»")
print("   - ç®€å•å¹³å‡ä¹Ÿå¾ˆç¨³å¥ï¼Œå¯ä½œä¸ºbaseline")

print("\n3ï¸âƒ£ ä½•æ—¶é›†æˆèƒ½æå‡æ€§èƒ½ï¼Ÿ")
print("   - åŸºæ¨¡å‹å·®å¼‚å¤§ï¼ˆå¦‚LSTM+CNN+XGBoostï¼‰")
print("   - åŸºæ¨¡å‹åœ¨ä¸åŒå­é—®é¢˜ä¸Šè¡¨ç°ä¸åŒ")
print("   - æœ‰è¶³å¤Ÿçš„å…ƒè®­ç»ƒæ•°æ®")

print("\n4ï¸âƒ£ ä½ çš„æƒ…å†µï¼š")
print(f"   - å•ä¸ªGRUå·²ç»å¾ˆå¼º (RÂ²={gru_val_r2:.4f})")
print("   - LSTMå’ŒGRUå¤ªç›¸ä¼¼ï¼Œé›†æˆæ”¶ç›Šæœ‰é™")
print("   - å»ºè®®ï¼šä½¿ç”¨GRUå•æ¨¡å‹æˆ–æ€§èƒ½åŠ æƒå¹³å‡")

print("\n" + "=" * 80)