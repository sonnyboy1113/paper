import os
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as plt
from math import sqrt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.linear_model import LinearRegression
from tensorflow.keras import Sequential, layers
from tensorflow.keras.callbacks import EarlyStopping
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# åŠ è½½æ•°æ®é›†
dataset = pd.read_csv('Corn-new.csv', parse_dates=['Date'], index_col=['Date'])
print(dataset.info())

# ========== æ•°æ®å‡†å¤‡ï¼šè®­ç»ƒé›†ã€æµ‹è¯•é›† ==========

# ç‰¹å¾æ•°æ®é›†å’Œæ ‡ç­¾æ•°æ®é›†
X = dataset.drop(columns=['Corn'], axis=1)
y = dataset['Corn']

# æ•°æ®é›†åˆ†ç¦»ï¼ˆè®­ç»ƒé›†80%ï¼Œæµ‹è¯•é›†20%ï¼‰
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False, random_state=666)

print(f"\næ•°æ®åˆ†å‰²:")
print(f"è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
print(f"æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")

# åªåœ¨è®­ç»ƒé›†ä¸Šfitå½’ä¸€åŒ–å™¨
feature_scalers = {}
for col in X_train.columns:
    scaler = MinMaxScaler()
    X_train[col] = scaler.fit_transform(X_train[col].values.reshape(-1, 1))
    X_test[col] = scaler.transform(X_test[col].values.reshape(-1, 1))
    feature_scalers[col] = scaler

# å¯¹æ ‡ç­¾è¿›è¡Œå½’ä¸€åŒ–
y_scaler = MinMaxScaler()
y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()
y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()

# è½¬æ¢å›Serieså¹¶ä¿æŒç´¢å¼•
y_train = pd.Series(y_train_scaled, index=y_train.index)
y_test = pd.Series(y_test_scaled, index=y_test.index)

# æ·»åŠ æ»åç‰¹å¾
for i in range(1, 6):
    X_train[f'Corn_lag_{i}'] = y_train.shift(i)
    X_test[f'Corn_lag_{i}'] = y_test.shift(i)

# åˆ é™¤å› æ»åç‰¹å¾äº§ç”Ÿçš„ç¼ºå¤±å€¼
X_train = X_train.dropna()
y_train = y_train.loc[X_train.index]

X_test = X_test.dropna()
y_test = y_test.loc[X_test.index]

print(f"\næ·»åŠ æ»åç‰¹å¾å:")
print(f"è®­ç»ƒé›†å½¢çŠ¶: X_train={X_train.shape}, y_train={y_train.shape}")
print(f"æµ‹è¯•é›†å½¢çŠ¶: X_test={X_test.shape}, y_test={y_test.shape}")

# æ„é€ ç‰¹å¾æ•°æ®é›†
def create_dataset(X, y, seq_len=5):
    features = []
    targets = []
    for i in range(0, len(X) - seq_len, 1):
        data = X.iloc[i:i + seq_len]
        label = y.iloc[i + seq_len]
        features.append(data)
        targets.append(label)
    return np.array(features), np.array(targets)

train_dataset, train_labels = create_dataset(X_train, y_train, seq_len=5)
test_dataset, test_labels = create_dataset(X_test, y_test, seq_len=5)

print(f"\nåºåˆ—æ•°æ®å½¢çŠ¶:")
print(f"train_dataset={train_dataset.shape}")
print(f"test_dataset={test_dataset.shape}")

# æ„é€ æ‰¹æ•°æ®
def create_batch_dataset(X, y, train=True, buffer_size=200, batch_size=32):
    batch_data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))
    if train:
        return batch_data.cache().shuffle(buffer_size).batch(batch_size)
    else:
        return batch_data.batch(batch_size)

train_batch_dataset = create_batch_dataset(train_dataset, train_labels)
test_batch_dataset = create_batch_dataset(test_dataset, test_labels, train=False)

# æ—©åœå›è°ƒï¼ˆä½¿ç”¨è®­ç»ƒé›†çš„ä¸€éƒ¨åˆ†ä½œä¸ºéªŒè¯é›†ï¼‰
early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1)

print("\n" + "="*80)
print("å¼€å§‹è®­ç»ƒæ‰€æœ‰æ¨¡å‹")
print("="*80)

# ======================= 1. è®­ç»ƒ LSTM æ¨¡å‹ =======================
print("\nã€æ¨¡å‹1ã€‘è®­ç»ƒ LSTM æ¨¡å‹...")
lstm_model = Sequential([
    layers.LSTM(units=100, input_shape=(5, 14)),
    layers.Dense(1)
])
lstm_model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))
lstm_history = lstm_model.fit(
    train_dataset, train_labels,  # ä½¿ç”¨numpyæ•°ç»„è€Œä¸æ˜¯tf.data.Dataset
    epochs=200,
    validation_split=0.2,
    batch_size=32,
    callbacks=[early_stop],
    verbose=0
)
print("âœ“ LSTM æ¨¡å‹è®­ç»ƒå®Œæˆ")

# ======================= 2. è®­ç»ƒ GRU æ¨¡å‹ =======================
print("\nã€æ¨¡å‹2ã€‘è®­ç»ƒ GRU æ¨¡å‹...")
gru_model = Sequential([
    layers.GRU(units=100, input_shape=(5, 14)),
    layers.Dense(1)
])
gru_model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))
gru_history = gru_model.fit(
    train_dataset, train_labels,
    epochs=200,
    validation_split=0.2,
    batch_size=32,
    callbacks=[early_stop],
    verbose=0
)
print("âœ“ GRU æ¨¡å‹è®­ç»ƒå®Œæˆ")

# ======================= 3. è®­ç»ƒå †å é›†æˆæ¨¡å‹ =======================
print("\nã€æ¨¡å‹3ã€‘è®­ç»ƒå †å é›†æˆæ¨¡å‹...")
print("  ä½¿ç”¨è®­ç»ƒé›†çš„é¢„æµ‹ç»“æœè®­ç»ƒçº¿æ€§å›å½’å…ƒæ¨¡å‹")

# åœ¨è®­ç»ƒé›†ä¸Šè·å–æ‰€æœ‰åŸºæ¨¡å‹çš„é¢„æµ‹ï¼ˆç”¨äºè®­ç»ƒå…ƒæ¨¡å‹ï¼‰
lstm_train_preds = lstm_model.predict(train_dataset, verbose=0)[:, 0]
gru_train_preds = gru_model.predict(train_dataset, verbose=0)[:, 0]

# å †å ç‰¹å¾
train_stacked_features = np.column_stack((lstm_train_preds, gru_train_preds))

# è®­ç»ƒå…ƒæ¨¡å‹
meta_model = LinearRegression()
meta_model.fit(train_stacked_features, train_labels)

print(f"  çº¿æ€§å›å½’ç³»æ•° [LSTM, GRU]: {meta_model.coef_}")
print(f"  æˆªè·: {meta_model.intercept_:.6f}")
print("âœ“ å †å é›†æˆæ¨¡å‹è®­ç»ƒå®Œæˆ")

# ======================= ç”Ÿæˆæ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹ =======================
print("\n" + "="*80)
print("ç”Ÿæˆæ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹ç»“æœ")
print("="*80)

# è®­ç»ƒé›†æœ€ç»ˆé¢„æµ‹
ensemble_train_preds = meta_model.predict(train_stacked_features)

# æµ‹è¯•é›†é¢„æµ‹
lstm_test_preds = lstm_model.predict(test_dataset, verbose=0)[:, 0]
gru_test_preds = gru_model.predict(test_dataset, verbose=0)[:, 0]

test_stacked = np.column_stack((lstm_test_preds, gru_test_preds))
ensemble_test_preds = meta_model.predict(test_stacked)

# ======================= æ€§èƒ½è¯„ä¼°å¯¹æ¯” =======================
print("\n" + "="*80)
print("æ¨¡å‹æ€§èƒ½å¯¹æ¯”ï¼ˆå½’ä¸€åŒ–æ•°æ®ï¼‰")
print("="*80)

models_info = {
    'LSTM': (lstm_train_preds, lstm_test_preds),
    'GRU': (gru_train_preds, gru_test_preds),
    'å †å é›†æˆ': (ensemble_train_preds, ensemble_test_preds)
}

print("\n{:<15} {:<15} {:<15}".format("æ¨¡å‹", "è®­ç»ƒé›†RÂ²", "æµ‹è¯•é›†RÂ²"))
print("-" * 50)
for name, (train_pred, test_pred) in models_info.items():
    train_r2 = r2_score(train_labels, train_pred)
    test_r2 = r2_score(test_labels, test_pred)
    print(f"{name:<15} {train_r2:<15.4f} {test_r2:<15.4f}")

# ======================= æµ‹è¯•é›†è¯¦ç»†æŒ‡æ ‡ =======================
print("\n" + "="*80)
print("æµ‹è¯•é›†è¯¦ç»†æ€§èƒ½æŒ‡æ ‡ï¼ˆå½’ä¸€åŒ–æ•°æ®ï¼‰")
print("="*80)

print("\n{:<15} {:<10} {:<10} {:<10} {:<10}".format("æ¨¡å‹", "RÂ²", "MAE", "RMSE", "MAPE"))
print("-" * 65)

for name, (_, test_pred) in models_info.items():
    r2 = r2_score(test_labels, test_pred)
    mae = mean_absolute_error(test_labels, test_pred)
    rmse = sqrt(mean_squared_error(test_labels, test_pred))
    mape = np.mean(np.abs((test_pred - test_labels) / (test_labels + 1e-8)))
    print(f"{name:<15} {r2:<10.4f} {mae:<10.6f} {rmse:<10.6f} {mape:<10.6f}")

# ========== åå½’ä¸€åŒ– ==========
test_labels_original = y_scaler.inverse_transform(test_labels.reshape(-1, 1))
lstm_preds_original = y_scaler.inverse_transform(lstm_test_preds.reshape(-1, 1))
gru_preds_original = y_scaler.inverse_transform(gru_test_preds.reshape(-1, 1))
ensemble_preds_original = y_scaler.inverse_transform(ensemble_test_preds.reshape(-1, 1))

# åŸå§‹å°ºåº¦è¯¦ç»†æŒ‡æ ‡
print("\n" + "="*80)
print("æµ‹è¯•é›†è¯¦ç»†æ€§èƒ½æŒ‡æ ‡ï¼ˆåŸå§‹å°ºåº¦ï¼‰")
print("="*80)

models_original = {
    'LSTM': lstm_preds_original,
    'GRU': gru_preds_original,
    'å †å é›†æˆ': ensemble_preds_original
}

print("\n{:<15} {:<10} {:<10} {:<10} {:<10}".format("æ¨¡å‹", "RÂ²", "MAE", "RMSE", "MAPE"))
print("-" * 65)

for name, preds in models_original.items():
    r2 = r2_score(test_labels_original, preds)
    mae = mean_absolute_error(test_labels_original, preds)
    rmse = sqrt(mean_squared_error(test_labels_original, preds))
    mape = np.mean(np.abs((preds - test_labels_original) / (test_labels_original + 1e-8)))
    print(f"{name:<15} {r2:<10.4f} {mae:<10.4f} {rmse:<10.4f} {mape:<10.6f}")

print("="*80)

# ======================= å¯è§†åŒ–ç»“æœ =======================
results_directory = "./Predict/"
if not os.path.exists(results_directory):
    os.makedirs(results_directory)

# 1. è®­ç»ƒè¿‡ç¨‹å¯¹æ¯”ï¼ˆåªæ˜¾ç¤ºLSTMå’ŒGRUï¼‰
fig_training = plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(lstm_history.history['loss'], label='è®­ç»ƒæŸå¤±', linewidth=2)
plt.plot(lstm_history.history['val_loss'], label='éªŒè¯æŸå¤±', linewidth=2)
plt.title('LSTM æ¨¡å‹è®­ç»ƒè¿‡ç¨‹', fontsize=13, fontweight='bold')
plt.xlabel('Epochs')
plt.ylabel('MSE Loss')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(gru_history.history['loss'], label='è®­ç»ƒæŸå¤±', linewidth=2)
plt.plot(gru_history.history['val_loss'], label='éªŒè¯æŸå¤±', linewidth=2)
plt.title('GRU æ¨¡å‹è®­ç»ƒè¿‡ç¨‹', fontsize=13, fontweight='bold')
plt.xlabel('Epochs')
plt.ylabel('MSE Loss')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(results_directory + 'models_training_loss.png', dpi=300, bbox_inches='tight')
plt.show(block=True)

# 2. æ‰€æœ‰æ¨¡å‹é¢„æµ‹å¯¹æ¯”ï¼ˆ1x3å¸ƒå±€ï¼‰
plt.figure(figsize=(18, 5))

plt.subplot(1, 3, 1)
plt.plot(test_labels_original, label="çœŸå®å€¼", linewidth=2.5, color='black')
plt.plot(lstm_preds_original, label="LSTMé¢„æµ‹", linewidth=2, alpha=0.8, color='blue')
plt.title("LSTM æ¨¡å‹", fontsize=14, fontweight='bold')
plt.xlabel('æ ·æœ¬åºå·', fontsize=11)
plt.ylabel('ç‰ç±³ä»·æ ¼', fontsize=11)
plt.legend(fontsize=10)
plt.grid(True, alpha=0.3)

plt.subplot(1, 3, 2)
plt.plot(test_labels_original, label="çœŸå®å€¼", linewidth=2.5, color='black')
plt.plot(gru_preds_original, label="GRUé¢„æµ‹", linewidth=2, alpha=0.8, color='green')
plt.title("GRU æ¨¡å‹", fontsize=14, fontweight='bold')
plt.xlabel('æ ·æœ¬åºå·', fontsize=11)
plt.ylabel('ç‰ç±³ä»·æ ¼', fontsize=11)
plt.legend(fontsize=10)
plt.grid(True, alpha=0.3)

plt.subplot(1, 3, 3)
plt.plot(test_labels_original, label="çœŸå®å€¼", linewidth=2.8, color='black', alpha=0.9)
plt.plot(lstm_preds_original, label="LSTM", linewidth=1.5, alpha=0.6, linestyle='--')
plt.plot(gru_preds_original, label="GRU", linewidth=1.5, alpha=0.6, linestyle='--')
plt.plot(ensemble_preds_original, label="å †å é›†æˆ", linewidth=2.5, alpha=0.9, color='red')
plt.title("æ‰€æœ‰æ¨¡å‹ç»¼åˆå¯¹æ¯”", fontsize=14, fontweight='bold')
plt.xlabel('æ ·æœ¬åºå·', fontsize=11)
plt.ylabel('ç‰ç±³ä»·æ ¼', fontsize=11)
plt.legend(fontsize=10, loc='best')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(results_directory + 'all_models_comparison.png', dpi=300, bbox_inches='tight')
plt.show(block=True)

# 3. æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”æŸ±çŠ¶å›¾
fig, axes = plt.subplots(2, 2, figsize=(16, 10))

metrics_data = {}
for name, preds in models_original.items():
    metrics_data[name] = {
        'RÂ²': r2_score(test_labels_original, preds),
        'MAE': mean_absolute_error(test_labels_original, preds),
        'RMSE': sqrt(mean_squared_error(test_labels_original, preds)),
        'MAPE': np.mean(np.abs((preds - test_labels_original) / (test_labels_original + 1e-8)))
    }

model_names = list(metrics_data.keys())
colors = ['blue', 'green', 'red']

# RÂ² å¯¹æ¯”
axes[0, 0].bar(model_names, [metrics_data[m]['RÂ²'] for m in model_names], color=colors, alpha=0.7)
axes[0, 0].set_title('RÂ² åˆ†æ•°å¯¹æ¯”', fontsize=13, fontweight='bold')
axes[0, 0].set_ylabel('RÂ² Score')
axes[0, 0].grid(True, alpha=0.3, axis='y')
axes[0, 0].tick_params(axis='x', rotation=15)

# MAE å¯¹æ¯”
axes[0, 1].bar(model_names, [metrics_data[m]['MAE'] for m in model_names], color=colors, alpha=0.7)
axes[0, 1].set_title('MAE å¯¹æ¯”', fontsize=13, fontweight='bold')
axes[0, 1].set_ylabel('MAE')
axes[0, 1].grid(True, alpha=0.3, axis='y')
axes[0, 1].tick_params(axis='x', rotation=15)

# RMSE å¯¹æ¯”
axes[1, 0].bar(model_names, [metrics_data[m]['RMSE'] for m in model_names], color=colors, alpha=0.7)
axes[1, 0].set_title('RMSE å¯¹æ¯”', fontsize=13, fontweight='bold')
axes[1, 0].set_ylabel('RMSE')
axes[1, 0].grid(True, alpha=0.3, axis='y')
axes[1, 0].tick_params(axis='x', rotation=15)

# MAPE å¯¹æ¯”
axes[1, 1].bar(model_names, [metrics_data[m]['MAPE'] for m in model_names], color=colors, alpha=0.7)
axes[1, 1].set_title('MAPE å¯¹æ¯”', fontsize=13, fontweight='bold')
axes[1, 1].set_ylabel('MAPE')
axes[1, 1].grid(True, alpha=0.3, axis='y')
axes[1, 1].tick_params(axis='x', rotation=15)

plt.tight_layout()
plt.savefig(results_directory + 'metrics_comparison.png', dpi=300, bbox_inches='tight')
plt.show(block=True)

# ======================= ä¿å­˜æ‰€æœ‰æ¨¡å‹ =======================
import pickle

with open(results_directory + 'stacked_scalers.pkl', 'wb') as f:
    pickle.dump({'feature_scalers': feature_scalers, 'y_scaler': y_scaler}, f)

with open(results_directory + 'linear_meta_model.pkl', 'wb') as f:
    pickle.dump(meta_model, f)

lstm_model.save(results_directory + 'lstm_model.h5')
gru_model.save(results_directory + 'gru_model.h5')

print('\n' + '='*80)
print('æ‰€æœ‰æ¨¡å‹ä¿å­˜å®Œæˆ')
print('='*80)
print('ä¿å­˜ä½ç½®:', results_directory)
print('  - lstm_model.h5             (LSTMæ¨¡å‹)')
print('  - gru_model.h5              (GRUæ¨¡å‹)')
print('  - linear_meta_model.pkl     (çº¿æ€§å›å½’å…ƒæ¨¡å‹)')
print('  - stacked_scalers.pkl       (å½’ä¸€åŒ–å™¨)')
print('='*80 + '\n')

# ======================= æœ€ç»ˆæ€»ç»“ =======================
print("="*80)
print("ğŸ‰ æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°å®Œæˆï¼")
print("="*80)
print(f"\nğŸ“Š ä½¿ç”¨çš„ä¸¤ä¸ªåŸºç¡€æ¨¡å‹: LSTM, GRU")
print(f"\nğŸ† æœ€ä½³å•æ¨¡å‹: GRU (æµ‹è¯•é›†RÂ²: {r2_score(test_labels_original, gru_preds_original):.4f})")
print(f"ğŸ¯ å †å é›†æˆæ¨¡å‹: æµ‹è¯•é›†RÂ²: {r2_score(test_labels_original, ensemble_preds_original):.4f}")
print(f"\nğŸ’¾ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° {results_directory} ç›®å½•")
print("="*80)