"""
æ”¯æŒèåˆæ¨¡å‹çš„é²æ£’æ€§æµ‹è¯• - é›†æˆä»£ç 
========================================

å°†æ­¤ä»£ç æ·»åŠ åˆ°ä¸»ä»£ç çš„æœ«å°¾ï¼Œæˆ–åˆ›å»ºä¸ºç‹¬ç«‹è„šæœ¬è¿è¡Œ

æ ¸å¿ƒæ”¹è¿›ï¼š
1. âœ… æ”¯æŒå®Œæ•´çš„ LSTM+GRU+XGBoost èåˆæ¨¡å‹
2. âœ… æ”¯æŒæ‰€æœ‰6ç§ç­–ç•¥çš„é²æ£’æ€§æµ‹è¯•
3. âœ… ä¿æŒæ»šåŠ¨çª—å£é¢„æµ‹ï¼Œé¿å…æ•°æ®æ³„éœ²
4. âœ… ç”Ÿæˆå®Œæ•´çš„é²æ£’æ€§æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
- å°†æ­¤ä»£ç æ·»åŠ åˆ°ä¸»ä»£ç çš„ SECTION 17 ä¹‹å
- æˆ–å•ç‹¬è¿è¡Œï¼ˆéœ€è¦å…ˆè¿è¡Œä¸»ä»£ç ç”Ÿæˆæ¨¡å‹ï¼‰
"""

import os
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib
matplotlib.use('TkAgg')
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from tensorflow.keras import Sequential, layers
from tensorflow.keras.callbacks import EarlyStopping
from xgboost import XGBRegressor
from math import sqrt
import matplotlib.pyplot as plt

# ä¸­æ–‡æ˜¾ç¤ºè®¾ç½®
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
class EnsembleRobustnessTester:
    """
    èåˆæ¨¡å‹é²æ£’æ€§æµ‹è¯•å™¨

    æ”¯æŒæµ‹è¯•ï¼š
    - LSTMå•æ¨¡å‹
    - GRUå•æ¨¡å‹
    - ç®€å•å¹³å‡
    - ç­–ç•¥1-6ï¼ˆæ®‹å·®å­¦ä¹ ç­‰ï¼‰
    """

    def __init__(self, data_path='Corn-new.csv', output_dir='./ensemble_robustness/'):
        self.data_path = data_path
        self.output_dir = output_dir

        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # åŠ è½½æ•°æ®
        self.dataset = pd.read_csv(data_path, parse_dates=['Date'], index_col='Date')

        # å­˜å‚¨ç»“æœ
        self.results = {}

        print(f"\nâœ… èåˆæ¨¡å‹é²æ£’æ€§æµ‹è¯•å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   æ•°æ®: {len(self.dataset)} æ ·æœ¬")
        print(f"   è¾“å‡º: {output_dir}")

    def train_ensemble_model(self, X_train_df, y_train_df, X_test_df, y_test_df,
                            strategy='gru_residual', verbose=False):
        """
        è®­ç»ƒå®Œæ•´çš„èåˆæ¨¡å‹ï¼ˆLSTM+GRU+XGBoostï¼‰

        Parameters:
            X_train_df: è®­ç»ƒç‰¹å¾ (DataFrame, åŸå§‹å°ºåº¦)
            y_train_df: è®­ç»ƒæ ‡ç­¾ (Series, åŸå§‹å°ºåº¦)
            X_test_df: æµ‹è¯•ç‰¹å¾ (DataFrame, åŸå§‹å°ºåº¦)
            y_test_df: æµ‹è¯•æ ‡ç­¾ (Series, åŸå§‹å°ºåº¦)
            strategy: èåˆç­–ç•¥
                - 'lstm': LSTMå•æ¨¡å‹
                - 'gru': GRUå•æ¨¡å‹
                - 'average': ç®€å•å¹³å‡
                - 'lstm_residual': ç­–ç•¥1-LSTMæ®‹å·®å­¦ä¹ 
                - 'gru_residual': ç­–ç•¥2-GRUæ®‹å·®å­¦ä¹ 
                - 'dual_residual': ç­–ç•¥3-åŒæ®‹å·®å­¦ä¹ 
                - 'gru_clipped': ç­–ç•¥4-æ®‹å·®å‰ªè£
                - 'gru_weighted': ç­–ç•¥5-åŠ æƒèåˆ
                - 'ultimate': ç­–ç•¥6-ç»ˆæç»„åˆ
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

        Returns:
            predictions: åŸå§‹å°ºåº¦çš„é¢„æµ‹å€¼
        """

        # ========== å‚æ•°é…ç½® ==========
        seq_len = 5
        lag_features = 5
        min_samples = 100

        # ========== æ•°æ®é‡æ£€æŸ¥ ==========
        if len(X_train_df) < min_samples:
            if verbose:
                print(f"  âš ï¸ è®­ç»ƒæ ·æœ¬è¿‡å°‘ ({len(X_train_df)})ï¼Œä½¿ç”¨åŸºçº¿é¢„æµ‹")
            return np.full(len(y_test_df), y_train_df.mean())

        # ========== æ•°æ®å½’ä¸€åŒ– ==========
        X_train = X_train_df.copy()
        X_test = X_test_df.copy()

        feature_scalers = {}
        for col in X_train_df.columns:
            scaler = MinMaxScaler()
            X_train[col] = scaler.fit_transform(X_train_df[col].values.reshape(-1, 1))
            X_test[col] = scaler.transform(X_test_df[col].values.reshape(-1, 1))
            feature_scalers[col] = scaler

        y_scaler = MinMaxScaler()
        y_train = y_scaler.fit_transform(y_train_df.values.reshape(-1, 1)).flatten()
        y_test = y_scaler.transform(y_test_df.values.reshape(-1, 1)).flatten()

        y_train = pd.Series(y_train, index=y_train_df.index)
        y_test = pd.Series(y_test, index=y_test_df.index)

        # ========== ç‰¹å¾å·¥ç¨‹ ==========
        def add_lag_features(X, y, n_lags=5):
            X_new = X.copy()
            for i in range(1, n_lags + 1):
                X_new[f'Corn_lag_{i}'] = y.shift(i)
            return X_new.dropna()

        X_train_feat = add_lag_features(X_train, y_train, lag_features)
        y_train_aligned = y_train.loc[X_train_feat.index]

        if len(X_train_feat) < 50:
            if verbose:
                print(f"  âš ï¸ ç‰¹å¾å·¥ç¨‹åæ ·æœ¬è¿‡å°‘ï¼Œä½¿ç”¨åŸºçº¿")
            return np.full(len(y_test_df), y_train_df.mean())

        # ========== åˆ›å»ºåºåˆ—æ•°æ® ==========
        def create_sequences(X, y, seq_len=5):
            X_seq, y_seq = [], []
            for i in range(len(X) - seq_len):
                X_seq.append(X.iloc[i:i + seq_len].values)
                y_seq.append(y.iloc[i + seq_len])
            return np.array(X_seq), np.array(y_seq)

        X_train_seq, y_train_seq = create_sequences(X_train_feat, y_train_aligned, seq_len)

        if len(X_train_seq) < 30:
            if verbose:
                print(f"  âš ï¸ åºåˆ—æ•°æ®è¿‡å°‘ï¼Œä½¿ç”¨åŸºçº¿")
            return np.full(len(y_test_df), y_train_df.mean())

        # ========== è®­ç»ƒLSTMæ¨¡å‹ ==========
        tf.random.set_seed(12)
        lstm_model = Sequential([
            layers.LSTM(80, input_shape=(seq_len, X_train_seq.shape[2]),
                       kernel_initializer=tf.keras.initializers.GlorotUniform(seed=12)),
            layers.Dropout(0.3, seed=12),
            layers.Dense(1, kernel_initializer=tf.keras.initializers.GlorotUniform(seed=12))
        ])
        lstm_model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(0.001))
        lstm_model.fit(X_train_seq, y_train_seq, validation_split=0.2,
                      epochs=50, batch_size=32,
                      callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],
                      verbose=0)

        # ========== è®­ç»ƒGRUæ¨¡å‹ ==========
        tf.random.set_seed(12)
        gru_model = Sequential([
            layers.GRU(100, input_shape=(seq_len, X_train_seq.shape[2]),
                      kernel_initializer=tf.keras.initializers.GlorotUniform(seed=12)),
            layers.Dropout(0.3, seed=12),
            layers.Dense(1, kernel_initializer=tf.keras.initializers.GlorotUniform(seed=12))
        ])
        gru_model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(0.001))
        gru_model.fit(X_train_seq, y_train_seq, validation_split=0.2,
                     epochs=50, batch_size=32,
                     callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],
                     verbose=0)

        # ========== ç”ŸæˆOOFé¢„æµ‹ï¼ˆç”¨äºè®­ç»ƒXGBoostï¼‰ ==========
        lstm_oof = lstm_model.predict(X_train_seq, verbose=0).flatten()
        gru_oof = gru_model.predict(X_train_seq, verbose=0).flatten()

        # ========== è®­ç»ƒXGBoost ==========
        if strategy in ['lstm_residual', 'gru_residual', 'dual_residual',
                       'gru_clipped', 'gru_weighted', 'ultimate']:
            X_train_flat = X_train_seq.reshape(len(X_train_seq), -1)
            X_xgb_train = np.hstack([
                X_train_flat,
                lstm_oof.reshape(-1, 1),
                gru_oof.reshape(-1, 1),
                ((lstm_oof + gru_oof) / 2).reshape(-1, 1),
                np.abs(lstm_oof - gru_oof).reshape(-1, 1)
            ])

            if strategy == 'lstm_residual':
                residual = y_train_seq - lstm_oof
            elif strategy in ['gru_residual', 'gru_clipped', 'gru_weighted', 'ultimate']:
                residual = y_train_seq - gru_oof
            else:  # dual_residual
                residual = y_train_seq - (lstm_oof + gru_oof) / 2

            xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.01, max_depth=3,
                                    random_state=42, verbosity=0)
            xgb_model.fit(X_xgb_train, residual)

        # ========== æ»šåŠ¨çª—å£é¢„æµ‹ ==========
        predictions_scaled = []
        history_X_feat = X_train_feat.tail(seq_len).copy()
        history_y = y_train_aligned.tail(lag_features).copy()

        for idx in range(len(X_test)):
            # æ„é€ å½“å‰æ ·æœ¬
            current_X_raw = X_test.iloc[idx:idx+1].copy()
            for i in range(1, lag_features + 1):
                current_X_raw[f'Corn_lag_{i}'] = history_y.iloc[-i] if len(history_y) >= i else 0

            current_window = pd.concat([history_X_feat.tail(seq_len-1), current_X_raw])
            X_seq = current_window.values.reshape(1, seq_len, -1)

            # è·å–LSTMå’ŒGRUé¢„æµ‹
            lstm_pred = lstm_model.predict(X_seq, verbose=0)[0, 0]
            gru_pred = gru_model.predict(X_seq, verbose=0)[0, 0]

            # æ ¹æ®ç­–ç•¥è®¡ç®—æœ€ç»ˆé¢„æµ‹
            if strategy == 'lstm':
                final_pred = lstm_pred
            elif strategy == 'gru':
                final_pred = gru_pred
            elif strategy == 'average':
                final_pred = (lstm_pred + gru_pred) / 2
            elif strategy == 'lstm_residual':
                X_flat = X_seq.reshape(1, -1)
                X_xgb = np.hstack([X_flat, [[lstm_pred, gru_pred, (lstm_pred+gru_pred)/2,
                                            abs(lstm_pred-gru_pred)]]])
                xgb_residual = xgb_model.predict(X_xgb)[0]
                final_pred = lstm_pred + xgb_residual
            elif strategy in ['gru_residual', 'gru_clipped', 'gru_weighted', 'ultimate']:
                X_flat = X_seq.reshape(1, -1)
                X_xgb = np.hstack([X_flat, [[lstm_pred, gru_pred, (lstm_pred+gru_pred)/2,
                                            abs(lstm_pred-gru_pred)]]])
                xgb_residual = xgb_model.predict(X_xgb)[0]

                if strategy == 'gru_residual':
                    final_pred = gru_pred + xgb_residual
                elif strategy == 'gru_clipped':
                    # ç®€åŒ–çš„æ®‹å·®å‰ªè£
                    clipped_residual = np.clip(xgb_residual, -0.1, 0.1)
                    final_pred = gru_pred + clipped_residual
                elif strategy == 'gru_weighted':
                    final_pred = gru_pred + 0.3 * xgb_residual
                else:  # ultimate
                    clipped_residual = np.clip(xgb_residual, -0.1, 0.1)
                    final_pred = gru_pred + 0.3 * clipped_residual
            elif strategy == 'dual_residual':
                X_flat = X_seq.reshape(1, -1)
                avg_pred = (lstm_pred + gru_pred) / 2
                X_xgb = np.hstack([X_flat, [[lstm_pred, gru_pred, avg_pred,
                                            abs(lstm_pred-gru_pred)]]])
                xgb_residual = xgb_model.predict(X_xgb)[0]
                final_pred = avg_pred + xgb_residual
            else:
                final_pred = (lstm_pred + gru_pred) / 2

            predictions_scaled.append(final_pred)

            # æ›´æ–°å†å²
            history_X_feat = pd.concat([history_X_feat.iloc[1:], current_X_raw])
            history_y = pd.concat([history_y.iloc[1:], pd.Series([y_test.iloc[idx]])])

        predictions_scaled = np.array(predictions_scaled)

        # ========== åå½’ä¸€åŒ– ==========
        predictions_original = y_scaler.inverse_transform(
            predictions_scaled.reshape(-1, 1)
        ).flatten()

        # ========== ç»“æœéªŒè¯ ==========
        if verbose:
            r2 = r2_score(y_test_df, predictions_original)
            mae = mean_absolute_error(y_test_df, predictions_original)
            print(f"  âœ“ ç­–ç•¥: {strategy}")
            print(f"  âœ“ RÂ²: {r2:.6f}, MAE: {mae:.2f}")

        return predictions_original

    def test_sub_periods(self, strategies=None):
        """
        å­æœŸé—´åˆ†æ - æµ‹è¯•æ‰€æœ‰ç­–ç•¥

        Parameters:
            strategies: è¦æµ‹è¯•çš„ç­–ç•¥åˆ—è¡¨
        """
        if strategies is None:
            strategies = ['gru', 'average', 'gru_residual', 'ultimate']

        print("\n" + "=" * 100)
        print("ã€èåˆæ¨¡å‹ã€‘å­æœŸé—´é²æ£’æ€§æµ‹è¯•".center(100))
        print("=" * 100)

        periods = {
            'ç–«æƒ…å‰ (2018-2019)': ('2018-01-01', '2019-12-31'),
            'ç–«æƒ…ä¸­ (2020-2021)': ('2020-01-01', '2021-12-31'),
            'å†²çªæœŸ (2022-2023)': ('2022-01-01', '2023-12-31')
        }

        all_results = []

        for period_name, (start_date, end_date) in periods.items():
            print(f"\n{'=' * 80}")
            print(f"æµ‹è¯•æ—¶æœŸ: {period_name}".center(80))
            print(f"{'=' * 80}")

            # ç­›é€‰æ•°æ®
            mask = (self.dataset.index >= start_date) & (self.dataset.index <= end_date)
            period_data = self.dataset[mask]

            if len(period_data) < 100:
                print(f"  âš ï¸ æ•°æ®é‡è¿‡å°‘ï¼Œè·³è¿‡")
                continue

            split_idx = int(len(period_data) * 0.8)
            X = period_data.drop(columns=['Corn'], axis=1)
            y = period_data['Corn']

            X_train = X.iloc[:split_idx]
            X_test = X.iloc[split_idx:]
            y_train = y.iloc[:split_idx]
            y_test = y.iloc[split_idx:]

            print(f"\næ•°æ®: è®­ç»ƒ{len(X_train)}æ ·æœ¬, æµ‹è¯•{len(X_test)}æ ·æœ¬")

            # æµ‹è¯•æ‰€æœ‰ç­–ç•¥
            for strategy in strategies:
                try:
                    predictions = self.train_ensemble_model(
                        X_train, y_train, X_test, y_test,
                        strategy=strategy, verbose=True
                    )

                    r2 = r2_score(y_test, predictions)
                    mae = mean_absolute_error(y_test, predictions)
                    rmse = sqrt(mean_squared_error(y_test, predictions))

                    all_results.append({
                        'æ—¶æœŸ': period_name,
                        'ç­–ç•¥': strategy,
                        'RÂ²': r2,
                        'MAE': mae,
                        'RMSE': rmse
                    })

                except Exception as e:
                    print(f"  âŒ ç­–ç•¥ {strategy} å¤±è´¥: {e}")

        # ä¿å­˜ç»“æœ
        results_df = pd.DataFrame(all_results)
        results_df.to_csv(f'{self.output_dir}sub_period_ensemble.csv', index=False)

        # å¯è§†åŒ–
        self._plot_sub_period_results(results_df, strategies)

        return results_df

    def _plot_sub_period_results(self, results_df, strategies):
        """ç»˜åˆ¶å­æœŸé—´ç»“æœ"""
        fig, axes = plt.subplots(1, len(strategies), figsize=(6*len(strategies), 5))

        if len(strategies) == 1:
            axes = [axes]

        periods = results_df['æ—¶æœŸ'].unique()
        x = np.arange(len(periods))

        for idx, strategy in enumerate(strategies):
            ax = axes[idx]
            strategy_data = results_df[results_df['ç­–ç•¥'] == strategy]

            r2_values = [strategy_data[strategy_data['æ—¶æœŸ']==p]['RÂ²'].values[0]
                        if len(strategy_data[strategy_data['æ—¶æœŸ']==p]) > 0 else 0
                        for p in periods]

            bars = ax.bar(x, r2_values, alpha=0.7, edgecolor='black')

            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, (bar, val) in enumerate(zip(bars, r2_values)):
                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(),
                       f'{val:.3f}', ha='center', va='bottom', fontweight='bold')

            ax.set_xticks(x)
            ax.set_xticklabels([p.split('(')[0].strip() for p in periods],
                              rotation=15, ha='right')
            ax.set_ylabel('RÂ² Score', fontweight='bold')
            ax.set_title(f'ç­–ç•¥: {strategy}', fontweight='bold')
            ax.axhline(y=0.7, color='green', linestyle='--', alpha=0.5, label='è‰¯å¥½çº¿')
            ax.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, label='åŠæ ¼çº¿')
            ax.legend()
            ax.grid(True, alpha=0.3, axis='y')

        plt.suptitle('èåˆæ¨¡å‹å­æœŸé—´é²æ£’æ€§åˆ†æ', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(f'{self.output_dir}sub_period_ensemble_comparison.png',
                   dpi=300, bbox_inches='tight')
        plt.show()

        print(f"\nâœ… å¯è§†åŒ–å·²ä¿å­˜: {self.output_dir}sub_period_ensemble_comparison.png")

    def generate_report(self):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        print("\n" + "=" * 100)
        print("èåˆæ¨¡å‹é²æ£’æ€§æ£€éªŒæŠ¥å‘Š".center(100))
        print("=" * 100)

        # è¯»å–ç»“æœ
        try:
            results_df = pd.read_csv(f'{self.output_dir}sub_period_ensemble.csv')

            report = []
            report.append("=" * 100)
            report.append("èåˆæ¨¡å‹é²æ£’æ€§æ£€éªŒæŠ¥å‘Š")
            report.append("=" * 100)
            report.append(f"\næµ‹è¯•ç­–ç•¥æ•°: {len(results_df['ç­–ç•¥'].unique())}")
            report.append(f"æµ‹è¯•æ—¶æœŸæ•°: {len(results_df['æ—¶æœŸ'].unique())}\n")

            # æŒ‰ç­–ç•¥æ±‡æ€»
            for strategy in results_df['ç­–ç•¥'].unique():
                strategy_data = results_df[results_df['ç­–ç•¥'] == strategy]
                report.append(f"\nã€ç­–ç•¥: {strategy}ã€‘")
                report.append("-" * 100)
                report.append(f"å¹³å‡ RÂ²: {strategy_data['RÂ²'].mean():.4f}")
                report.append(f"RÂ² èŒƒå›´: [{strategy_data['RÂ²'].min():.4f}, {strategy_data['RÂ²'].max():.4f}]")
                report.append(f"RÂ² æ ‡å‡†å·®: {strategy_data['RÂ²'].std():.4f}")

                if strategy_data['RÂ²'].std() < 0.1:
                    report.append("âœ… è¯¥ç­–ç•¥åœ¨å„æ—¶æœŸè¡¨ç°ç¨³å®š")
                else:
                    report.append("âš ï¸ è¯¥ç­–ç•¥å­˜åœ¨æ—¶æœŸæ•æ„Ÿæ€§")

            report_text = '\n'.join(report)

            with open(f'{self.output_dir}ensemble_robustness_report.txt', 'w',
                     encoding='utf-8') as f:
                f.write(report_text)

            print(report_text)
            print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜: {self.output_dir}ensemble_robustness_report.txt")

        except FileNotFoundError:
            print("âš ï¸ æœªæ‰¾åˆ°æµ‹è¯•ç»“æœï¼Œè¯·å…ˆè¿è¡Œ test_sub_periods()")


# =====================================================================
# ä½¿ç”¨ç¤ºä¾‹ï¼šå°†æ­¤ä»£ç æ·»åŠ åˆ°ä¸»ä»£ç çš„ SECTION 17 ä¹‹å
# =====================================================================

if __name__ == "__main__":
    print("\n" + "=" * 100)
    print("å¼€å§‹èåˆæ¨¡å‹é²æ£’æ€§æµ‹è¯•".center(100))
    print("=" * 100)

    # åˆ›å»ºæµ‹è¯•å™¨
    tester = EnsembleRobustnessTester(
        data_path='Corn-new.csv',
        output_dir='./ensemble_robustness/'
    )

    # æµ‹è¯•å¤šä¸ªç­–ç•¥
    test_strategies = [
        'gru',              # GRUå•æ¨¡å‹ï¼ˆåŸºå‡†ï¼‰
        'average',          # ç®€å•å¹³å‡
        'gru_residual',     # ç­–ç•¥2-GRUæ®‹å·®å­¦ä¹ 
        'ultimate'          # ç­–ç•¥6-ç»ˆæç»„åˆ
    ]

    # è¿è¡Œå­æœŸé—´æµ‹è¯•
    results = tester.test_sub_periods(strategies=test_strategies)

    # ç”ŸæˆæŠ¥å‘Š
    tester.generate_report()

    print("\n" + "=" * 100)
    print("âœ… èåˆæ¨¡å‹é²æ£’æ€§æµ‹è¯•å®Œæˆï¼".center(100))
    print("ğŸ“ ç»“æœä¿å­˜åœ¨: ./ensemble_robustness/".center(100))
    print("=" * 100)