import os
import random
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib

matplotlib.use('TkAgg')
import matplotlib.pyplot as plt
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from math import sqrt
from tensorflow.keras import Sequential, layers
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.regularizers import l2
import warnings

warnings.filterwarnings('ignore')


# ========================================
# å›ºå®šæ‰€æœ‰éšæœºç§å­ - ç¡®ä¿ç»“æœå¯é‡å¤
# ========================================
def set_seed(seed=42):
    """
    å›ºå®šæ‰€æœ‰éšæœºæ€§æ¥æºï¼Œç¡®ä¿å®éªŒç»“æœå¯é‡å¤

    å‚æ•°:
        seed: éšæœºç§å­å€¼ï¼Œé»˜è®¤42
    """
    # Pythonå†…ç½®randomæ¨¡å—
    random.seed(seed)

    # Numpyéšæœºæ•°
    np.random.seed(seed)

    # TensorFlowéšæœºæ•°
    tf.random.set_seed(seed)

    # ç¯å¢ƒå˜é‡è®¾ç½®
    os.environ['PYTHONHASHSEED'] = str(seed)
    os.environ['TF_DETERMINISTIC_OPS'] = '1'
    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'

    # ç¡®ä¿TensorFlowä½¿ç”¨ç¡®å®šæ€§ç®—æ³•
    tf.config.experimental.enable_op_determinism()

    print(f"âœ… å·²å›ºå®šæ‰€æœ‰éšæœºç§å­: {seed}")
    print(f"âœ… å®éªŒç»“æœç°åœ¨å®Œå…¨å¯é‡å¤\n")


# åœ¨æ‰€æœ‰æ“ä½œä¹‹å‰è°ƒç”¨
set_seed(42)

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

print("=" * 100)
print("ç‰¹å¾æ¶ˆèç ”ç©¶ - é‡åŒ–æ¯ä¸ªå› ç´ çš„è´¡çŒ®åº¦ (å›ºå®šç§å­ç‰ˆæœ¬)".center(100))
print("=" * 100)


class AblationStudy:
    """ç‰¹å¾æ¶ˆèç ”ç©¶ç±» - å›ºå®šç§å­ç‰ˆæœ¬"""

    def __init__(self, data_path='Corn-new.csv', output_dir='./ablation_results/',
                 model_type='lstm', random_seed=42):
        """
        åˆå§‹åŒ–æ¶ˆèç ”ç©¶

        å‚æ•°:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
                - 'gru': å•å±‚GRU
            random_seed: éšæœºç§å­
        """
        self.data_path = data_path
        self.output_dir = output_dir
        self.model_type = model_type
        self.random_seed = random_seed

        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # ç‰¹å¾åç§°å’Œæè¿°
        self.feature_info = {
            'TR': 'å›½å€ºåˆ©ç‡',
            'IR': 'åˆ©ç‡',
            'ER': 'æ±‡ç‡',
            'ine': 'åŸæ²¹æœŸè´§ä»·æ ¼',
            'FP.CFI': 'å†œäº§å“æœŸè´§æŒ‡æ•°',
            'CFD': 'ç¾å›½ç‰ç±³æœŸè´§ä»·æ ¼',
            'GPR': 'åœ°ç¼˜æ”¿æ²»é£é™©',
            'EPU': 'ç»æµæ”¿ç­–ä¸ç¡®å®šæ€§'
        }

        self.results = {}
        self.baseline_performance = None

        print(f"\nğŸ“‹ æ¶ˆèç ”ç©¶é…ç½®:")
        print(f"  ä½¿ç”¨æ¨¡å‹: {model_type.upper()}")
        print(f"  éšæœºç§å­: {random_seed}")
        if model_type == 'lstm':
            print(f"  è¯´æ˜: å•å±‚LSTMï¼Œå¿«é€Ÿä¸”ç¨³å®šï¼Œé€‚åˆæ¶ˆèç ”ç©¶")
        elif model_type == 'gru':
            print(f"  è¯´æ˜: å•å±‚GRUï¼Œè®¡ç®—æ•ˆç‡é«˜")


    def load_and_preprocess_data(self, features_to_use=None):
        """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
        # åŠ è½½æ•°æ®
        dataset = pd.read_csv(self.data_path, parse_dates=['Date'], index_col=['Date'])

        X = dataset.drop(columns=['Corn'], axis=1)
        y = dataset['Corn']

        # é€‰æ‹©ç‰¹å¾
        if features_to_use is not None:
            X = X[features_to_use]

        # åˆ†å‰²æ•°æ®
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

        # å½’ä¸€åŒ–
        feature_scalers = {}
        X_train_scaled = X_train.copy()
        X_test_scaled = X_test.copy()

        for col in X_train.columns:
            scaler = MinMaxScaler()
            X_train_scaled[col] = scaler.fit_transform(X_train[col].values.reshape(-1, 1))
            X_test_scaled[col] = scaler.transform(X_test[col].values.reshape(-1, 1))
            feature_scalers[col] = scaler

        y_scaler = MinMaxScaler()
        y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()
        y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()

        return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, y_scaler

    def add_lag_features(self, X, y, n_lags=5):
        """æ·»åŠ æ»åç‰¹å¾"""
        X_new = X.copy()
        for i in range(1, n_lags + 1):
            X_new[f'Corn_lag_{i}'] = y.shift(i)
        return X_new.dropna()

    def create_sequences(self, X, y, seq_len=5):
        """åˆ›å»ºåºåˆ—æ•°æ®"""
        X_seq, y_seq = [], []
        for i in range(len(X) - seq_len):
            X_seq.append(X.iloc[i:i + seq_len].values)
            y_seq.append(y.iloc[i + seq_len])
        return np.array(X_seq), np.array(y_seq)

    def build_lstm_model(self, input_shape):
        """æ„å»ºLSTMæ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆ - ç”¨äºå¿«é€Ÿæ¶ˆèç ”ç©¶ï¼‰"""
        model = Sequential([
            layers.LSTM(
                units=80,
                input_shape=input_shape,
                kernel_regularizer=l2(0.01),
                recurrent_regularizer=l2(0.01)
            ),
            layers.Dropout(0.3),
            layers.Dense(1)
        ])
        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))
        return model

    def build_gru_model(self, input_shape):
        """æ„å»ºGRUæ¨¡å‹"""
        model = Sequential([
            layers.GRU(units=100, input_shape=input_shape),
            layers.Dropout(0.3),
            layers.Dense(1)
        ])
        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))
        return model


    def train_and_evaluate(self, features_to_use, experiment_name):
        """è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹"""
        print(f"\n{'=' * 80}")
        print(f"å®éªŒ: {experiment_name}".center(80))
        print(f"ä½¿ç”¨ç‰¹å¾: {features_to_use}".center(80))
        print(f"{'=' * 80}")

        # åœ¨æ¯æ¬¡è®­ç»ƒå‰é‡æ–°è®¾ç½®ç§å­ï¼Œç¡®ä¿å®Œå…¨å¯é‡å¤
        set_seed(self.random_seed)

        # åŠ è½½æ•°æ®
        X_train, X_test, y_train, y_test, y_scaler = self.load_and_preprocess_data(features_to_use)

        # è½¬æ¢ä¸ºSeriesä»¥ä¾¿æ·»åŠ æ»åç‰¹å¾
        y_train_series = pd.Series(y_train, index=X_train.index)
        y_test_series = pd.Series(y_test, index=X_test.index)

        # æ·»åŠ æ»åç‰¹å¾
        X_train_feat = self.add_lag_features(X_train, y_train_series)
        y_train_aligned = y_train_series.loc[X_train_feat.index]

        X_test_feat = self.add_lag_features(X_test, y_test_series)
        y_test_aligned = y_test_series.loc[X_test_feat.index]

        # åˆ›å»ºåºåˆ—
        seq_len = 5
        X_train_seq, y_train_seq = self.create_sequences(X_train_feat, y_train_aligned, seq_len)
        X_test_seq, y_test_seq = self.create_sequences(X_test_feat, y_test_aligned, seq_len)

        print(f"è®­ç»ƒé›†: {X_train_seq.shape}, æµ‹è¯•é›†: {X_test_seq.shape}")

        # æ ¹æ®model_typeæ„å»ºä¸åŒçš„æ¨¡å‹
        if self.model_type == 'lstm':
            model = self.build_lstm_model((X_train_seq.shape[1], X_train_seq.shape[2]))
        elif self.model_type == 'gru':
            model = self.build_gru_model((X_train_seq.shape[1], X_train_seq.shape[2]))
        else:
            raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {self.model_type}")

        early_stop = EarlyStopping(
            monitor='val_loss',
            patience=15,
            restore_best_weights=True,
            verbose=0
        )

        history = model.fit(
            X_train_seq, y_train_seq,
            validation_split=0.2,
            epochs=100,
            batch_size=32,
            callbacks=[early_stop],
            verbose=0
        )

        # é¢„æµ‹
        y_train_pred = model.predict(X_train_seq, verbose=0).flatten()
        y_test_pred = model.predict(X_test_seq, verbose=0).flatten()

        # è®¡ç®—æŒ‡æ ‡
        metrics = {
            'train_r2': r2_score(y_train_seq, y_train_pred),
            'test_r2': r2_score(y_test_seq, y_test_pred),
            'test_mae': mean_absolute_error(y_test_seq, y_test_pred),
            'test_rmse': sqrt(mean_squared_error(y_test_seq, y_test_pred)),
            'test_mape': np.mean(np.abs((y_test_pred - y_test_seq) / (y_test_seq + 1e-8))),
            'n_features': X_train_seq.shape[2],
            'features': features_to_use
        }

        print(f"\næ€§èƒ½æŒ‡æ ‡:")
        print(f"  è®­ç»ƒRÂ²: {metrics['train_r2']:.6f}")
        print(f"  æµ‹è¯•RÂ²: {metrics['test_r2']:.6f}")
        print(f"  æµ‹è¯•MAE: {metrics['test_mae']:.6f}")
        print(f"  æµ‹è¯•RMSE: {metrics['test_rmse']:.6f}")
        print(f"  æµ‹è¯•MAPE: {metrics['test_mape']:.6f}")

        return metrics

    def run_full_ablation(self):
        """è¿è¡Œå®Œæ•´çš„æ¶ˆèç ”ç©¶"""
        all_features = list(self.feature_info.keys())

        # 1. åŸºçº¿å®éªŒï¼šä½¿ç”¨æ‰€æœ‰ç‰¹å¾
        print("\n" + "=" * 100)
        print("ã€åŸºçº¿å®éªŒã€‘ä½¿ç”¨æ‰€æœ‰ç‰¹å¾".center(100))
        print("=" * 100)

        baseline_metrics = self.train_and_evaluate(
            all_features,
            "åŸºçº¿æ¨¡å‹ï¼ˆæ‰€æœ‰ç‰¹å¾ï¼‰"
        )
        self.baseline_performance = baseline_metrics
        self.results['Baseline'] = baseline_metrics

        # 2. å•ç‰¹å¾æ¶ˆèï¼šé€ä¸ªç§»é™¤ç‰¹å¾
        print("\n" + "=" * 100)
        print("ã€å•ç‰¹å¾æ¶ˆèã€‘é€ä¸ªç§»é™¤ç‰¹å¾".center(100))
        print("=" * 100)

        for feature in all_features:
            remaining_features = [f for f in all_features if f != feature]
            experiment_name = f"ç§»é™¤ {feature} ({self.feature_info[feature]})"

            metrics = self.train_and_evaluate(
                remaining_features,
                experiment_name
            )
            self.results[f'Remove_{feature}'] = metrics

        # 3. å•ç‰¹å¾å®éªŒï¼šä»…ä½¿ç”¨å•ä¸ªç‰¹å¾
        print("\n" + "=" * 100)
        print("ã€å•ç‰¹å¾å®éªŒã€‘ä»…ä½¿ç”¨å•ä¸ªç‰¹å¾".center(100))
        print("=" * 100)

        for feature in all_features:
            experiment_name = f"ä»…ä½¿ç”¨ {feature} ({self.feature_info[feature]})"

            metrics = self.train_and_evaluate(
                [feature],
                experiment_name
            )
            self.results[f'Only_{feature}'] = metrics

    def calculate_feature_importance(self):
        """è®¡ç®—ç‰¹å¾é‡è¦æ€§"""
        baseline_r2 = self.baseline_performance['test_r2']

        importance_scores = {}

        for feature in self.feature_info.keys():
            # ç§»é™¤è¯¥ç‰¹å¾åçš„æ€§èƒ½ä¸‹é™
            remove_key = f'Remove_{feature}'
            if remove_key in self.results:
                remove_r2 = self.results[remove_key]['test_r2']
                drop_score = baseline_r2 - remove_r2  # æ€§èƒ½ä¸‹é™ = ç§»é™¤åä¸‹é™çš„RÂ²

            # ä»…ä½¿ç”¨è¯¥ç‰¹å¾çš„æ€§èƒ½
            only_key = f'Only_{feature}'
            if only_key in self.results:
                only_r2 = self.results[only_key]['test_r2']
                standalone_score = only_r2  # å•ç‹¬æ€§èƒ½

            importance_scores[feature] = {
                'name': self.feature_info[feature],
                'drop_score': drop_score,  # ç§»é™¤åæ€§èƒ½ä¸‹é™ï¼ˆè¶Šå¤§è¶Šé‡è¦ï¼‰
                'standalone_score': standalone_score,  # å•ç‹¬ä½¿ç”¨æ€§èƒ½
                'combined_score': (drop_score + standalone_score) / 2  # ç»¼åˆå¾—åˆ†
            }

        return importance_scores

    def visualize_results(self):
        """å¯è§†åŒ–ç»“æœ"""
        importance_scores = self.calculate_feature_importance()

        # å‡†å¤‡æ•°æ®
        features = list(importance_scores.keys())
        feature_names = [importance_scores[f]['name'] for f in features]
        drop_scores = [importance_scores[f]['drop_score'] for f in features]
        standalone_scores = [importance_scores[f]['standalone_score'] for f in features]
        combined_scores = [importance_scores[f]['combined_score'] for f in features]

        # æ’åº
        sorted_indices = np.argsort(combined_scores)[::-1]
        features = [features[i] for i in sorted_indices]
        feature_names = [feature_names[i] for i in sorted_indices]
        drop_scores = [drop_scores[i] for i in sorted_indices]
        standalone_scores = [standalone_scores[i] for i in sorted_indices]
        combined_scores = [combined_scores[i] for i in sorted_indices]

        # å›¾1: ç‰¹å¾é‡è¦æ€§ç»¼åˆå¯¹æ¯”
        fig, axes = plt.subplots(2, 2, figsize=(18, 12))

        # 1.1 ç§»é™¤åæ€§èƒ½ä¸‹é™
        ax1 = axes[0, 0]
        colors1 = plt.cm.Reds(np.linspace(0.4, 0.9, len(features)))
        bars1 = ax1.barh(range(len(features)), drop_scores, color=colors1, alpha=0.8)
        ax1.set_yticks(range(len(features)))
        ax1.set_yticklabels([f"{features[i]}\n({feature_names[i]})" for i in range(len(features))], fontsize=9)
        ax1.set_xlabel('æ€§èƒ½ä¸‹é™ (Î”RÂ²)', fontsize=11, fontweight='bold')
        ax1.set_title('ç§»é™¤ç‰¹å¾åçš„æ€§èƒ½ä¸‹é™\nï¼ˆè¶Šå¤§è¡¨ç¤ºè¯¥ç‰¹å¾è¶Šé‡è¦ï¼‰', fontsize=12, fontweight='bold')
        ax1.grid(True, alpha=0.3, axis='x')

        for i, (bar, score) in enumerate(zip(bars1, drop_scores)):
            ax1.text(bar.get_width() + 0.002, bar.get_y() + bar.get_height() / 2,
                     f'{score:.4f}', ha='left', va='center', fontweight='bold', fontsize=9)

        # 1.2 å•ç‹¬ä½¿ç”¨æ€§èƒ½
        ax2 = axes[0, 1]
        colors2 = plt.cm.Blues(np.linspace(0.4, 0.9, len(features)))
        bars2 = ax2.barh(range(len(features)), standalone_scores, color=colors2, alpha=0.8)
        ax2.set_yticks(range(len(features)))
        ax2.set_yticklabels([f"{features[i]}\n({feature_names[i]})" for i in range(len(features))], fontsize=9)
        ax2.set_xlabel('RÂ² Score', fontsize=11, fontweight='bold')
        ax2.set_title('å•ç‹¬ä½¿ç”¨ç‰¹å¾çš„æ€§èƒ½\nï¼ˆè¡¡é‡ç‰¹å¾çš„ç‹¬ç«‹é¢„æµ‹èƒ½åŠ›ï¼‰', fontsize=12, fontweight='bold')
        ax2.grid(True, alpha=0.3, axis='x')

        for i, (bar, score) in enumerate(zip(bars2, standalone_scores)):
            ax2.text(bar.get_width() + 0.002, bar.get_y() + bar.get_height() / 2,
                     f'{score:.4f}', ha='left', va='center', fontweight='bold', fontsize=9)

        # 1.3 ç»¼åˆé‡è¦æ€§å¾—åˆ†
        ax3 = axes[1, 0]
        colors3 = plt.cm.Greens(np.linspace(0.4, 0.9, len(features)))
        bars3 = ax3.barh(range(len(features)), combined_scores, color=colors3, alpha=0.8)
        ax3.set_yticks(range(len(features)))
        ax3.set_yticklabels([f"{features[i]}\n({feature_names[i]})" for i in range(len(features))], fontsize=9)
        ax3.set_xlabel('ç»¼åˆå¾—åˆ†', fontsize=11, fontweight='bold')
        ax3.set_title('ç‰¹å¾ç»¼åˆé‡è¦æ€§å¾—åˆ†\nï¼ˆç§»é™¤å½±å“ + ç‹¬ç«‹æ€§èƒ½ï¼‰/2', fontsize=12, fontweight='bold')
        ax3.grid(True, alpha=0.3, axis='x')

        for i, (bar, score) in enumerate(zip(bars3, combined_scores)):
            ax3.text(bar.get_width() + 0.002, bar.get_y() + bar.get_height() / 2,
                     f'{score:.4f}', ha='left', va='center', fontweight='bold', fontsize=9)

        # 1.4 é›·è¾¾å›¾
        ax4 = axes[1, 1]
        ax4.remove()
        ax4 = fig.add_subplot(2, 2, 4, projection='polar')

        top5_features = features[:5]
        top5_names = feature_names[:5]

        angles = np.linspace(0, 2 * np.pi, len(top5_features), endpoint=False).tolist()
        angles += angles[:1]

        for idx, (feature, name) in enumerate(zip(top5_features, top5_names)):
            values = [
                importance_scores[feature]['drop_score'] / max(drop_scores),
                importance_scores[feature]['standalone_score'] / max(standalone_scores)
            ]
            values = values + values[:1]

            plot_angles = [0, np.pi] + [0]
            ax4.plot(plot_angles, values, 'o-', linewidth=2, label=f"{feature} ({name})")
            ax4.fill(plot_angles, values, alpha=0.15)

        ax4.set_xticks([0, np.pi])
        ax4.set_xticklabels(['ç§»é™¤å½±å“', 'ç‹¬ç«‹æ€§èƒ½'])
        ax4.set_ylim(0, 1)
        ax4.set_title('Top5ç‰¹å¾å¤šç»´åº¦å¯¹æ¯”', fontsize=12, fontweight='bold', pad=20)
        ax4.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=8)
        ax4.grid(True)

        plt.suptitle(f'ç‰¹å¾æ¶ˆèç ”ç©¶ - å›ºå®šç§å­={self.random_seed}',
                     fontsize=14, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(f'{self.output_dir}feature_importance_analysis_{self.model_type}_seed{self.random_seed}.png',
                    dpi=300, bbox_inches='tight')
        plt.show()
        print(f"\nâœ… ç‰¹å¾é‡è¦æ€§åˆ†æå›¾å·²ä¿å­˜")

        # å›¾2: æ‰€æœ‰å®éªŒå¯¹æ¯”
        self.plot_all_experiments()

    def plot_all_experiments(self):
        """ç»˜åˆ¶æ‰€æœ‰å®éªŒå¯¹æ¯”"""
        fig, ax = plt.subplots(figsize=(16, 10))

        experiment_names = []
        r2_scores = []
        colors_list = []

        # åŸºçº¿
        experiment_names.append('åŸºçº¿ï¼ˆæ‰€æœ‰ç‰¹å¾ï¼‰')
        r2_scores.append(self.results['Baseline']['test_r2'])
        colors_list.append('gold')

        # ç§»é™¤ç‰¹å¾å®éªŒ
        for feature in self.feature_info.keys():
            key = f'Remove_{feature}'
            if key in self.results:
                experiment_names.append(f'ç§»é™¤ {feature}')
                r2_scores.append(self.results[key]['test_r2'])
                colors_list.append('coral')

        # å•ç‰¹å¾å®éªŒ
        for feature in self.feature_info.keys():
            key = f'Only_{feature}'
            if key in self.results:
                experiment_names.append(f'ä»… {feature}')
                r2_scores.append(self.results[key]['test_r2'])
                colors_list.append('skyblue')

        # ç»˜åˆ¶
        bars = ax.barh(range(len(experiment_names)), r2_scores, color=colors_list, alpha=0.7)

        # åŸºçº¿å‚è€ƒçº¿
        baseline_r2 = self.results['Baseline']['test_r2']
        ax.axvline(x=baseline_r2, color='red', linestyle='--', linewidth=2,
                   label=f'åŸºçº¿ RÂ²={baseline_r2:.6f}', alpha=0.7)

        # æ ‡æ³¨
        for i, (bar, r2) in enumerate(zip(bars, r2_scores)):
            diff = r2 - baseline_r2
            label = f'{r2:.6f}'
            if i > 0:  # éåŸºçº¿å®éªŒ
                if diff >= 0:
                    label += f' (+{diff:.6f})'
                    color = 'green'
                else:
                    label += f' ({diff:.6f})'
                    color = 'red'
            else:
                color = 'black'

            ax.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height() / 2,
                    label, ha='left', va='center', fontweight='bold', fontsize=8, color=color)

        ax.set_yticks(range(len(experiment_names)))
        ax.set_yticklabels(experiment_names, fontsize=9)
        ax.set_xlabel('RÂ² Score', fontsize=12, fontweight='bold')
        ax.set_title(f'æ¶ˆèç ”ç©¶ - æ‰€æœ‰å®éªŒæ€§èƒ½å¯¹æ¯”\n(æ¨¡å‹: {self.model_type.upper()}, ç§å­: {self.random_seed})',
                     fontsize=14, fontweight='bold')
        ax.legend(fontsize=11)
        ax.grid(True, alpha=0.3, axis='x')

        plt.tight_layout()
        plt.savefig(f'{self.output_dir}all_experiments_comparison_{self.model_type}_seed{self.random_seed}.png',
                    dpi=300, bbox_inches='tight')
        plt.show()
        print(f"âœ… æ‰€æœ‰å®éªŒå¯¹æ¯”å›¾å·²ä¿å­˜")

    def generate_report(self):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        importance_scores = self.calculate_feature_importance()

        print("\n" + "=" * 100)
        print("æ¶ˆèç ”ç©¶è¯¦ç»†æŠ¥å‘Š (å›ºå®šç§å­ç‰ˆæœ¬)".center(100))
        print("=" * 100)

        print(f"\nã€å®éªŒé…ç½®ã€‘")
        print(f"  ä½¿ç”¨æ¨¡å‹: {self.model_type.upper()}")
        print(f"  éšæœºç§å­: {self.random_seed}")
        print(f"  ç‰¹å¾æ€»æ•°: {len(self.feature_info)}")
        print(f"  ç»“æœå¯é‡å¤æ€§: âœ… å®Œå…¨å¯é‡å¤")

        # åŸºçº¿æ€§èƒ½
        print(f"\nã€åŸºçº¿æ€§èƒ½ã€‘ä½¿ç”¨æ‰€æœ‰{len(self.feature_info)}ä¸ªç‰¹å¾")
        print(f"  æµ‹è¯•RÂ²: {self.baseline_performance['test_r2']:.6f}")
        print(f"  æµ‹è¯•MAE: {self.baseline_performance['test_mae']:.6f}")
        print(f"  æµ‹è¯•RMSE: {self.baseline_performance['test_rmse']:.6f}")

        # ç‰¹å¾é‡è¦æ€§æ’å
        print(f"\nã€ç‰¹å¾é‡è¦æ€§æ’åã€‘")
        print(f"{'æ’å':<6} {'ç‰¹å¾':<10} {'ä¸­æ–‡å':<15} {'ç§»é™¤å½±å“':<12} {'ç‹¬ç«‹æ€§èƒ½':<12} {'ç»¼åˆå¾—åˆ†':<12}")
        print("-" * 85)

        sorted_features = sorted(
            importance_scores.items(),
            key=lambda x: x[1]['combined_score'],
            reverse=True
        )

        for rank, (feature, scores) in enumerate(sorted_features, 1):
            emoji = "ğŸ¥‡" if rank == 1 else "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰" if rank == 3 else "  "
            print(f"{emoji} {rank:<4} {feature:<10} {scores['name']:<15} "
                  f"{scores['drop_score']:.6f}     {scores['standalone_score']:.6f}     "
                  f"{scores['combined_score']:.6f}")

        # å…³é”®å‘ç°
        print(f"\nã€å…³é”®å‘ç°ã€‘")
        top_feature = sorted_features[0]
        print(f"  ğŸ† æœ€é‡è¦ç‰¹å¾: {top_feature[0]} ({top_feature[1]['name']})")
        print(f"     - ç§»é™¤åæ€§èƒ½ä¸‹é™: {top_feature[1]['drop_score']:.6f}")
        print(f"     - å•ç‹¬ä½¿ç”¨æ€§èƒ½: {top_feature[1]['standalone_score']:.6f}")

        weakest_feature = sorted_features[-1]
        print(f"  âš ï¸  æœ€å¼±ç‰¹å¾: {weakest_feature[0]} ({weakest_feature[1]['name']})")
        print(f"     - ç§»é™¤åæ€§èƒ½ä¸‹é™: {weakest_feature[1]['drop_score']:.6f}")
        print(f"     - å•ç‹¬ä½¿ç”¨æ€§èƒ½: {weakest_feature[1]['standalone_score']:.6f}")

        # ä¿å­˜CSVæŠ¥å‘Š
        report_data = []
        for feature, scores in sorted_features:
            report_data.append({
                'ç‰¹å¾ä»£ç ': feature,
                'ç‰¹å¾åç§°': scores['name'],
                'ç§»é™¤åæ€§èƒ½ä¸‹é™': scores['drop_score'],
                'å•ç‹¬ä½¿ç”¨æ€§èƒ½': scores['standalone_score'],
                'ç»¼åˆé‡è¦æ€§å¾—åˆ†': scores['combined_score']
            })

        df_report = pd.DataFrame(report_data)
        df_report.to_csv(f'{self.output_dir}ablation_study_report_{self.model_type}_seed{self.random_seed}.csv',
                         index=False, encoding='utf-8-sig')
        print(f"\nâœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {self.output_dir}ablation_study_report_{self.model_type}_seed{self.random_seed}.csv")


# ========================================
# ä¸»ç¨‹åºæ‰§è¡Œ
# ========================================
if __name__ == "__main__":
    print("\n" + "=" * 100)
    print("ç‰¹å¾æ¶ˆèç ”ç©¶ - æ¨¡å‹é€‰æ‹© (å›ºå®šç§å­ç‰ˆæœ¬)".center(100))
    print("=" * 100)
    print("\nå¯é€‰æ¨¡å‹ç±»å‹:")
    print("  1. 'lstm'    - å•å±‚LSTMï¼ˆæ¨èï¼šå¿«é€Ÿä¸”ç¨³å®šï¼‰â­")
    print("  2. 'gru'     - å•å±‚GRUï¼ˆè®¡ç®—æ•ˆç‡é«˜ï¼‰")
    print("\n" + "=" * 100)

    # é€‰æ‹©æ¨¡å‹ç±»å‹å’Œéšæœºç§å­
    # æ–¹å¼1: ç›´æ¥æŒ‡å®šï¼ˆæ¨èç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
    #model_choice = 'gru'  # æ”¹ä¸º 'gru'ä»¥ä½¿ç”¨å…¶ä»–æ¨¡å‹
    #random_seed = 42  # å›ºå®šç§å­ï¼Œç¡®ä¿ç»“æœå¯é‡å¤

    # æ–¹å¼2: äº¤äº’å¼é€‰æ‹©ï¼ˆå–æ¶ˆæ³¨é‡Šä»¥å¯ç”¨ï¼‰
    model_choice = input("\nè¯·é€‰æ‹©æ¨¡å‹ç±»å‹ (lstm/gruï¼Œé»˜è®¤gru): ").strip().lower()
    if model_choice not in ['lstm', 'gru']:
         model_choice = 'gru'

    seed_input = input("è¯·è¾“å…¥éšæœºç§å­ (é»˜è®¤42): ").strip()
    random_seed = int(seed_input) if seed_input.isdigit() else 42

    print(f"\nğŸ¯ å¼€å§‹æ¶ˆèç ”ç©¶...")
    print(f"  æ¨¡å‹: {model_choice.upper()}")
    print(f"  ç§å­: {random_seed}")
    print(f"  ç»“æœå°†å®Œå…¨å¯é‡å¤ï¼")

    # åˆ›å»ºæ¶ˆèç ”ç©¶å¯¹è±¡
    study = AblationStudy(
        data_path='Corn-new.csv',
        output_dir='./ablation_results/',
        model_type=model_choice,
        random_seed=random_seed
    )

    # è¿è¡Œå®Œæ•´çš„æ¶ˆèç ”ç©¶
    study.run_full_ablation()

    # å¯è§†åŒ–ç»“æœ
    study.visualize_results()

    # ç”ŸæˆæŠ¥å‘Š
    study.generate_report()

    print("\n" + "=" * 100)
    print("æ¶ˆèç ”ç©¶å®Œæˆï¼".center(100))
    print(f"ä½¿ç”¨æ¨¡å‹: {model_choice.upper()}, éšæœºç§å­: {random_seed}".center(100))
    print("âœ… æ‰€æœ‰ç»“æœå®Œå…¨å¯é‡å¤ï¼".center(100))
    print("=" * 100)

    print("\nğŸ“Œ ä½¿ç”¨æç¤º:")
    print("  - æ¯æ¬¡è¿è¡Œç›¸åŒçš„ç§å­ï¼Œç»“æœå°†å®Œå…¨ä¸€è‡´")
    print("  - å¦‚éœ€æµ‹è¯•ç»“æœç¨³å®šæ€§ï¼Œå¯å°è¯•ä¸åŒçš„ç§å­å€¼ (å¦‚ 42, 123, 999)")
    print("  - æ‰€æœ‰å›¾è¡¨å’ŒæŠ¥å‘Šå·²ä¿å­˜åˆ° ./ablation_results/ ç›®å½•")
    print("  - æ–‡ä»¶ååŒ…å«æ¨¡å‹ç±»å‹å’Œç§å­å€¼ï¼Œæ–¹ä¾¿å¯¹æ¯”ä¸åŒé…ç½®")